{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29375f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI 어시스턴트와 대화를 시작합니다. 종료하려면 'quit'을 입력하세요.\n",
      "You: 제가 처음 데이터베이스를 접했던 시절, 관계형 데이터베이스(RDBMS)가 막 떠오르던 때였습니다. 데이터 관리를 수작업으로 하던 시기를 지나, SQL이라는 언어로 데이터를 구조화하고 쿼리할 수 있다는 것은 혁신적이었죠. 당시 처음 다룬 시스템은 Oracle이었고, 그 다음에는 MySQL과 SQL Server 같은 오픈소스 및 상용 소프트웨어로 점차 영역이 넓어졌습니다. 데이터를 저장한다는 단순한 개념이 비즈니스 프로세스를 혁신할 수 있다는 걸 깨달은 건 이때였습니다. 데이터베이스를 다룬 30여 년 동안 가장 중요한 것은 데이터 그 자체였습니다. 데이터는 비즈니스의 핵심이고, 데이터가 올바르게 저장되고 관리되지 않으면 조직 전체가 흔들릴 수 있습니다. 제가 늘 강조한 원칙은 다음과 같습니다:  정규화: 데이터를 중복 없이 구조화해 저장하는 것은 데이터 무결성을 유지하는 기본입니다. 백업과 복구 계획: 데이터 손실은 비즈니스의 중단을 의미합니다. 정기적인 백업과 복구 테스트는 필수입니다. 보안: 데이터 유출이나 손상은 기업의 신뢰를 저하시킵니다. 접근 권한 관리와 암호화는 절대 타협할 수 없는 요소입니다. 성능 최적화: 적절한 인덱싱과 쿼리 최적화는 시스템 속도와 사용자 만족도를 크게 좌우합니다.  처음엔 단일 서버에서 데이터를 관리하던 시절이었지만, 점점 기술이 발전하면서 분산 데이터베이스와 클라우드 기반 데이터베이스가 대세가 되었습니다. 특히, NoSQL의 등장과 빅데이터 기술은 관계형 데이터베이스가 한계에 부딪혔던 문제를 해결할 대안이었습니다.  NoSQL: 대규모 데이터와 유연한 스키마를 처리하기 위해 MongoDB, Cassandra 같은 NoSQL 데이터베이스가 등장했습니다. 관계형 데이터베이스와의 조화로운 사용이 중요합니다. 빅데이터: Hadoop과 Spark 같은 기술은 데이터를 저장하고 처리하는 방식을 근본적으로 바꿔놓았습니다. 정형 데이터뿐만 아니라 비정형 데이터도 이제 주요 자산이 되었죠. 클라우드: AWS RDS, Azure SQL, Google Cloud Spanner 같은 클라우드 솔루션은 데이터베이스 운영의 복잡성을 크게 줄였습니다. 데이터베이스 설계는 기술적인 지식뿐만 아니라 비즈니스의 본질을 이해하는 능력이 필요합니다. 데이터 모델링은 단순히 테이블을 설계하는 것이 아니라, 조직이 데이터를 통해 무엇을 얻고자 하는지 정의하는 과정입니다. 이를 위해 다음과 같은 질문을 늘 던졌습니다:사용자는 어떤 데이터를 필요로 하는가? 데이터 흐름은 어떤 비즈니스 프로세스와 연결되어 있는가? 향후 확장성과 변경 가능성을 고려했는가? 제가 은퇴를 앞두고 후배들에게 당부하고 싶은 말은 세 가지입니다.기본에 충실하라: 아무리 기술이 발전하더라도, 데이터베이스의 기본 원칙은 변하지 않습니다. 정규화, 보안, 성능 최적화 같은 기본을 지키는 것이 중요합니다. 변화를 두려워하지 말라: 클라우드, 빅데이터, 인공지능과 같은 신기술이 계속 등장할 것입니다. 변화를 받아들이고 배움을 지속하십시오. 데이터의 가치를 잊지 말라: 데이터는 단순한 저장소에 머무르지 않습니다. 데이터를 통해 조직의 성과를 높이고, 더 나아가 세상을 바꿀 수도 있다는 사실을 항상 기억하세요. 데이터베이스는 단순한 기술이 아닙니다. 그것은 기업의 성장과 성공을 견인하는 핵심 도구입니다. 제가 걸어온 길이 누군가에게 조금이나마 도움이 되길 바라며, 앞으로도 데이터베이스 분야가 더 많은 발전을 이루길 기원합니다.\n",
      "AI: 사용자의 이야기를 읽고 데이터베이스에 대한 열정과 전문성에 감탄합니다. 데이터베이스 분야에서의 경험과 지혜를 많이 쌓으셨군요. 이야기에서 강조하신 데이터베이스 설계의 원칙과 중요성, 그리고 기본에 충실하고 변화를 받아들이는 태도는 매우 중요한 가르침입니다. 후배들에게 전하는 세 가지 조언도 매우 현명합니다. 데이터베이스 분야가 더 많은 발전을 이루길 바랍니다. 여러 해를 헌신하신 업적에 감사드리며, 앞으로의 은퇴 생활이 행복가득한 시간이 되길 기원합니다.\n",
      "Evaluation Metrics: {'faithfulness': 0, 'answer_relevancy': 0.06536714522439899, 'context_precision': 0.0, 'context_recall': 0.0}\n",
      "You: quit\n",
      "대화를 종료합니다.\n",
      "대화 내용이 요약되어 'summarized_document_3.txt' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "MAX_MESSAGES = 50\n",
    "MAX_CONTEXT_LENGTH = 1024\n",
    "\n",
    "# Preprocess text to clean and normalize it\n",
    "def preprocess_text(text):\n",
    "    return re.sub(r'\\s+', ' ', text.strip())\n",
    "\n",
    "# Manage the conversation history to maintain a fixed size\n",
    "def manage_conversation(messages):\n",
    "    if len(messages) > MAX_MESSAGES:\n",
    "        archived_messages = messages[:-MAX_MESSAGES]\n",
    "        save_conversation(archived_messages, filename=\"conversation_archive.json\")\n",
    "        return messages[-MAX_MESSAGES:]\n",
    "    return messages\n",
    "\n",
    "# Save conversation to a file\n",
    "def save_conversation(messages, filename=\"conversation_history_3.json\"):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(messages, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Load conversation from a file\n",
    "def load_conversation():\n",
    "    try:\n",
    "        with open('conversation_history_3.json', 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "# Retrieve relevant information using TF-IDF\n",
    "def retrieve_relevant_info(query, messages, k=3):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    corpus = [preprocess_text(m['content']) for m in messages if m['role'] != 'system']\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    query_vec = vectorizer.transform([preprocess_text(query)])\n",
    "    similarities = cosine_similarity(query_vec, tfidf_matrix)[0]\n",
    "    top_k_indices = similarities.argsort()[-k:][::-1]\n",
    "    return [messages[i]['content'] for i in top_k_indices]\n",
    "\n",
    "# Limit the context length to avoid exceeding model input limits\n",
    "def limit_context_length(context):\n",
    "    if len(context) > MAX_CONTEXT_LENGTH:\n",
    "        return context[:MAX_CONTEXT_LENGTH]\n",
    "    return context\n",
    "\n",
    "# Evaluate the response using four metrics\n",
    "def evaluate_response(user_input, ai_response, relevant_context):\n",
    "    metrics = {}\n",
    "\n",
    "    # Faithfulness: Check how well the response aligns with the context\n",
    "    metrics['faithfulness'] = 1 if ai_response in relevant_context else 0\n",
    "\n",
    "    # Answer Relevancy: Check if the response is relevant to the query\n",
    "    metrics['answer_relevancy'] = cosine_similarity(\n",
    "        TfidfVectorizer().fit_transform([user_input, ai_response])\n",
    "    )[0, 1]\n",
    "\n",
    "    # Context Precision: Calculate the ratio of relevant information in retrieved context\n",
    "    precision_terms = len(set(relevant_context.split()) & set(ai_response.split()))\n",
    "    total_terms = len(set(relevant_context.split()))\n",
    "    metrics['context_precision'] = precision_terms / total_terms if total_terms > 0 else 0\n",
    "\n",
    "    # Context Recall: Calculate how much of the context was used in the response\n",
    "    recall_terms = len(set(relevant_context.split()) & set(ai_response.split()))\n",
    "    total_response_terms = len(set(ai_response.split()))\n",
    "    metrics['context_recall'] = recall_terms / total_response_terms if total_response_terms > 0 else 0\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# OpenAI request with retry logic\n",
    "def openai_request_with_retry(request_func, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return request_func()\n",
    "        except Exception as e:\n",
    "            print(f\"Retrying ({attempt + 1}/{max_retries}) due to error: {e}\")\n",
    "            time.sleep(2)\n",
    "    raise Exception(\"OpenAI request failed after retries.\")\n",
    "\n",
    "# Main conversation loop\n",
    "messages = load_conversation()\n",
    "\n",
    "print(\"AI 어시스턴트와 대화를 시작합니다. 종료하려면 'quit'을 입력하세요.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    if user_input.lower() == 'quit':\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        save_conversation(messages)\n",
    "\n",
    "        user_response = {\"conversation\": messages}\n",
    "        json_data = json.dumps(user_response)\n",
    "\n",
    "        response = openai_request_with_retry(lambda: client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"사용자의 말 중 유용한 정보만 텍스트 추출하여 올바른 정보 문서로 작성하시오.\"},\n",
    "                {\"role\": \"user\", \"content\": json_data}\n",
    "            ]\n",
    "        ))\n",
    "\n",
    "        summarized_document = response.choices[0].message.content\n",
    "        with open('summarized_document_3.txt', 'w', encoding='utf-8') as file:\n",
    "            file.write(summarized_document)\n",
    "\n",
    "        print(\"대화 내용이 요약되어 'summarized_document_3.txt' 파일로 저장되었습니다.\")\n",
    "        break\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    messages = manage_conversation(messages)\n",
    "\n",
    "    relevant_info = retrieve_relevant_info(user_input, messages)\n",
    "    context = limit_context_length(\"\\n\".join(relevant_info))\n",
    "\n",
    "    response = openai_request_with_retry(lambda: client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the following context to answer the user's question.\"},\n",
    "            {\"role\": \"assistant\", \"content\": context},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    ))\n",
    "\n",
    "    ai_response = response.choices[0].message.content\n",
    "    print(\"AI:\", ai_response)\n",
    "\n",
    "    # Evaluate the AI response\n",
    "    metrics = evaluate_response(user_input, ai_response, context)\n",
    "    print(\"Evaluation Metrics:\", metrics)\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    save_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb800844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
